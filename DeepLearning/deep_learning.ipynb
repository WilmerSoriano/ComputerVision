{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21827823",
   "metadata": {},
   "source": [
    "## **Basic CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e704190",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "For this run, I build a basic CNN starting with the file provide: *getting_started.ipynb*.\n",
    "1. The dataset, model fitting, and evaluation on the test set remain the same.  \n",
    "   The only changes made were to the estimator and forward functions. These define the CNN architecture.\n",
    "\n",
    "2. I started by adding 3 convolutional layers (then changed it to 4 after testing, accuracy increased by 5%).  \n",
    "   Since the images are grayscale, the input channel is 1. Each convolution layer increases the output channels, doubling them (e.g., 32 => 64 => 128).\n",
    "   All convolutions use a 3x3 kernel.\n",
    "\n",
    "3. Before Max pooling, accurary hit around 30%, after adding Max Pooling it went up by 55%. Max pooling lower the size of the feature and reduce computation time.  \n",
    "   It also helps the model focus on the most important features.\n",
    "\n",
    "4. Before passing the output to the Fully Connected Layer, we flatten the multi dimensions into a single vector.\n",
    "\n",
    "5. Finaly, the Fully Cconnected Layer (or in this case the nn.Linear) maps the feature vector to a 10 class output.  \n",
    "   To calculate the input size of this layer, we need to know the output size after the last convolution.  \n",
    "   After the last convolution (Conv2d(64, 128, 3x3)), the output feature map size is 10×10.  \n",
    "   Therefore, the flattened vector size is:  \n",
    "   128 (# of channels) x 10W x 10H = Size of the vector.\n",
    "\n",
    "# Results\n",
    "\n",
    "- **Training Loss:** 0.1973  \n",
    "- **Validation Loss:** 1.91  \n",
    "- **Test Accuracy:** 56.96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53cc395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "class BaselineModel(L.LightningModule):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.estimator = nn.Sequential( # UPDATE: This section now handle convolution with kernel size 3x3, and max pooling, .\n",
    "            nn.Conv2d(1, 32, (3,3)), # Where (channel, Output feature, kernel)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 2x2 max pooling \n",
    "            nn.Conv2d(32, 64, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(128*10*10, num_classes) # Changed Fully connected Layer to work with output size 64=>31=>14=> 12 => 10(Added another layer)\n",
    "        )\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.estimator(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.accuracy(y_hat, y)\n",
    "\n",
    "        self.log(\"val_accuracy\", self.accuracy)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.accuracy(y_hat, y)\n",
    "\n",
    "        self.log(\"test_accuracy\", self.accuracy)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19a2c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import Imagenette\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Prepare the dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=False, transform=train_transforms)\n",
    "\n",
    "# Use 10% of the training set for validation\n",
    "train_set_size = int(len(train_dataset) * 0.9)\n",
    "val_set_size = len(train_dataset) - train_set_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_set_size, val_set_size], generator=seed)\n",
    "val_dataset.dataset.transform = test_transforms\n",
    "\n",
    "# Use DataLoader to load the dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
    "\n",
    "# Configure the test dataset\n",
    "test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=False, transform=test_transforms)\n",
    "\n",
    "model = BaselineModel()\n",
    "\n",
    "# Add EarlyStopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                                    mode=\"min\",\n",
    "                                    patience=5)\n",
    "\n",
    "# Configure Checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75bd2e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | estimator | Sequential         | 257 K  | train\n",
      "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "257 K     Trainable params\n",
      "0         Non-trainable params\n",
      "257 K     Total params\n",
      "1.030     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 67/67 [01:43<00:00,  0.65it/s, v_num=7]         \n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60814ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5696815252304077\n",
      "        test_loss            1.975080132484436\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 11.21it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.5723336935043335\n",
      "        val_loss            1.9177066087722778\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wilme\\miniconda3\\envs\\cse4310a3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 67/67 [00:07<00:00,  8.39it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9428538084030151\n",
      "        val_loss            0.19738364219665527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, num_workers=8, shuffle=False)\n",
    "trainer.test(model=model, dataloaders=test_loader)\n",
    "\n",
    "val_result = trainer.validate(model=model, dataloaders=val_loader)\n",
    "print(\"TRAINING Result (ignore the naming convention)\")\n",
    "train_result = trainer.validate(model=model, dataloaders=train_loader) # Using validation report, instead of making a custom training report. Result are correct, just subtitle are wrong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769b9e9",
   "metadata": {},
   "source": [
    "## **All Convolutional Net**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VS2",
   "language": "python",
   "name": "cse4310a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
